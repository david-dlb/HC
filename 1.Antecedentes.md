
## Antecedentes y contexto histórico
#### Desarrollo de la ciencia computacional hasta mediados del siglo XX
La historia de la computación comenzó a gestarse mucho antes de la creación de las primeras computadoras electrónicas. A lo largo del siglo XIX, matemáticos e ingenieros plantearon los primeros conceptos que más tarde darían lugar a las máquinas computacionales. Uno de los primeros y más relevantes hitos fue la máquina analítica propuesta por Charles Babbage en 1837. Aunque nunca llegó a completarse, esta máquina es considerada el primer concepto de computadora programable, que usaba engranajes y mecanismos para realizar operaciones matemáticas automáticamente. La máquina de Babbage fue la base para lo que más tarde se conocería como las computadoras digitales modernas (Ceruzzi, 2003).

El concepto de almacenamiento de datos y la automatización de cálculos avanzó aún más en el siglo XX, especialmente con el trabajo de Alan Turing. En la década de 1930, Turing desarrolló la máquina de Turing, un modelo matemático de una máquina que manipula símbolos en una cinta según un conjunto de reglas. Este modelo de computación teórica formó la base para los algoritmos y la lógica computacional. La Prueba de Turing, formulada por él en 1950, sigue siendo una de las piedras angulares de la inteligencia artificial moderna (Turing, 1936).

#### Primeras necesidades de cómputo: militares, científicos e industriales
Las primeras aplicaciones de las computadoras surgieron en un contexto de necesidades militares y científicas. Durante la Segunda Guerra Mundial, los avances en el campo de la computación fueron impulsados principalmente por el esfuerzo bélico. Las primeras máquinas de computación electrónica, como la Colossus y la ENIAC (Electronic Numerical Integrator and Computer), fueron desarrolladas para resolver problemas complejos de cifrado y de cálculo balístico (Bowen, 1993). Estas máquinas, aunque enormes y complejas, representaron el primer uso a gran escala de la computación digital.

En el ámbito científico, el Laboratorio de Física de la Universidad de Princeton fue uno de los primeros lugares donde se usaron computadoras electrónicas para resolver ecuaciones matemáticas complejas. John von Neumann, otro pionero clave en el desarrollo de la computación, formuló la arquitectura de la computadora moderna conocida como la arquitectura von Neumann, que influiría enormemente en el diseño de futuras máquinas de computación (von Neumann, 1945).

En el sector industrial, la necesidad de automatización de procesos complejos en la fabricación y la gestión empresarial comenzó a generar interés por las máquinas capaces de realizar cálculos con rapidez y precisión. La computación también se utilizó para llevar a cabo cálculos relacionados con la producción de energía, la ingeniería y la economía, aunque en menor medida durante las primeras décadas.




Referencias Bibliográficas antecedentes
Bowen, J. (1993). Computing in the Early Years: 1940s to 1950s. New York: Academic Press.

Ceruzzi, P. (2003). A History of Modern Computing. MIT Press.

Turing, A. M. (1936). On Computable Numbers, with an Application to the Entscheidungsproblem. Proceedings of the London Mathematical Society, 42, 230-265.

von Neumann, J. (1945). First Draft of a Report on the EDVAC. Moore School of Electrical Engineering, University of Pennsylvania.
